{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6904cd",
   "metadata": {},
   "source": [
    "## Populate FASTianF1 RDF database\n",
    "\n",
    "This notebook reports the main steps to download CSV files, process them and create an RDF dataset from them accordingly to an ontology.\n",
    "\n",
    "To measure execution time in Jupyter notebooks: <code>pip install ipython-autotime</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATE \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa963",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "circuitsUrl = path + '/data/kaggle/circuits.csv'\n",
    "constructor_resultsUrl = path + '/data/kaggle/constructor_results.csv'\n",
    "constructor_standingsUrl = path + '/data/kaggle/constructor_standings.csv'\n",
    "constructorsUrl = path + '/data/kaggle/constructors.csv'\n",
    "driver_standingsUrl = path + '/data/kaggle/driver_standings.csv'\n",
    "driversUrl = path + '/data/kaggle/drivers.csv'\n",
    "lap_timesUrl = path + '/data/kaggle/lap_times.csv'\n",
    "pit_stopsUrl = path + '/data/kaggle/pit_stops.csv'\n",
    "qualifyingUrl = path + '/data/kaggle/qualifying.csv'\n",
    "racesUrl = path + '/data/kaggle/races.csv'\n",
    "resultsUrl = path + '/data/kaggle/results.csv'\n",
    "sprint_resultsUrl = path + '/data/kaggle/sprint_results.csv'\n",
    "\n",
    "# country codes\n",
    "countriesURL = path + '/data/countryCodes/wikipedia-iso-country-codes.csv'\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '/data/rdf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e71b5",
   "metadata": {},
   "source": [
    "# Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the movie ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "FO = Namespace(\"http://www.dei.unipd.it/database2/FASTianF1ontology#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7880d54",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf231c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the country codes\n",
    "# we need to convert NaN values to something else otherwise NA strings are converted to NaN -> problem with Namibia\n",
    "countries = pd.read_csv(countriesURL, sep=',', index_col='Name', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8b325",
   "metadata": {},
   "source": [
    "# Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a236e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "drivers = pd.read_csv(driversUrl, sep=',', index_col='driverId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in drivers.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Driver = URIRef(FO[\"driver\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Driver, RDF.type, FO.Driver))\n",
    "    g.add((Driver, FO['hasDriverRef'], Literal(row['driverRef'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((Driver, FO['hasCode'], Literal(row['code'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasForename'], Literal(row['forename'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasSurname'], Literal(row['surname'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasDateOfBirth'], Literal(row['dob'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "   \n",
    "    try:\n",
    "        datetime.datetime.strptime(str(row['dob']), '%Y-%m-%d')\n",
    "        g.add((Driver, FO['hasDOB'], Literal(row['dob'], datatype=XSD.date)))\n",
    "    except ValueError:\n",
    "        # probably it's the year alone\n",
    "        # check length\n",
    "        if (len(row['dob'])==4):\n",
    "            #it is a year\n",
    "            g.add((Driver, FO['hasDOB'], Literal(row['dob']+\"-01-01\", datatype=XSD.date)))\n",
    "\n",
    "    ## handle country\n",
    "    #there can be more than one country per movie\n",
    "    for c in str(row['nationality']).split('-'):\n",
    "        cName = c.strip()\n",
    "        # check if the country exists\n",
    "        # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "        if((countries.index == cName).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "            code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "            # create the RDF node\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Movie and the Country \n",
    "            g.add((Driver, FO['hasNationality'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'drivers.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa815a7",
   "metadata": {},
   "source": [
    "# Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e32881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "circuits = pd.read_csv(circuitsUrl, sep=',', index_col='circuitId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in circuits.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Circuit = URIRef(FO[\"circuit\"+str(index)])\n",
    "    Location = URIRef(FO[\"location\"+str(row['location'])])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Circuit, RDF.type, FO.Circuit))\n",
    "    g.add((Circuit, FO['hasCircuitRef'], Literal(row['circuitRef'], datatype=XSD.string)))\n",
    "    g.add((Circuit, FO['hasName'], Literal(row['name'], datatype=XSD.integer)))\n",
    "    g.add((Location, RDF.type, FO.Location))\n",
    "    g.add((Circuit, FO['hasLocation'], Location))\n",
    "    g.add((Circuit, FO['hasLat'], Literal(row['lat'], datatype=XSD.integer)))\n",
    "    g.add((Circuit, FO['hasLng'], Literal(row['lng'], datatype=XSD.integer)))\n",
    "    g.add((Circuit, FO['hasAlt'], Literal(row['alt'], datatype=XSD.integer)))\n",
    "    g.add((Circuit, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "\n",
    "    ## handle country\n",
    "    cName = c.strip(str(row['country']))\n",
    "    # check if the country exists\n",
    "    # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "    if((countries.index == cName).any() == True):\n",
    "        #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "        code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "        # create the RDF node\n",
    "        Country = URIRef(CNS[code])\n",
    "        # add the edge connecting the Movie and the Country \n",
    "        g.add((Location, FO['hasCountry'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'circuits.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab133277",
   "metadata": {},
   "source": [
    "# Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6908695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "constructors = pd.read_csv(constructosUrl, sep=',', index_col='constructorId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c69926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in constructors.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Constructor = URIRef(FO[\"constructor\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Constructor, RDF.type, FO.Constructor))\n",
    "    g.add((Constructor, FO['hasConstructorRef'], Literal(row['constructorRef'], datatype=XSD.string)))\n",
    "    g.add((Constructor, FO['hasName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Constructor, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "\n",
    "    ## handle country\n",
    "    #there can be more than one country per movie\n",
    "    for c in str(row['nationality']).split('-'):\n",
    "        cName = c.strip()\n",
    "        # check if the country exists\n",
    "        # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "        if((countries.index == cName).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "            code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "            # create the RDF node\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Movie and the Country \n",
    "            g.add((Constructor, FO['hasNationality'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59913aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'constructors.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577738ca",
   "metadata": {},
   "source": [
    "# Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c60ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "status = pd.read_csv(statusUrl, sep=',', index_col='statusId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in status.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Status = URIRef(FO[\"status\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Status, RDF.type, FO.Status))\n",
    "    g.add((Status, FO['hasName'], Literal(row['status'], datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'status.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dcd70b",
   "metadata": {},
   "source": [
    "# Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e22c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "races = pd.read_csv(racesUrl, sep=',', index_col='raceId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in races.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Race = URIRef(FO[\"race\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Race, RDF.type, FO.Race))\n",
    "    g.add((Race, FO['hasRound'], Literal(row['round'], datatype=XSD.integer)))\n",
    "    g.add((Race, FO['hasName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Race, FO['hasDate'], Literal(row['date'], datatype=XSD.date)))\n",
    "    g.add((Race, FO['hasTime'], Literal(row['time'], datatype=XSD.time)))\n",
    "    g.add((Race, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "    \n",
    "    Circuit = URIRef(FO[\"circuit\"+str(row['circuitId'])])\n",
    "    g.add((Race, FO['hasCircuit'], Circuit))\n",
    "    \n",
    "    Season = URIRef(FO[\"season\"+str(row['year'])])\n",
    "    g.add((Season, RDF.type, FO.Season))\n",
    "    g.add((Season, FO['hasYear'], Literal(row['year'], datatype=XSD.integer)))\n",
    "    g.add((Race, FO['inSeason'], Season))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'race.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f27d02",
   "metadata": {},
   "source": [
    "# Race (partecipations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5804573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "r_partecipations = pd.read_csv(resultsUrl, sep=',', index_col='resultId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf33c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in r_partecipations.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    R_partecipation = URIRef(FO[\"r_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((R_partecipation, RDF.type, FO.RacePartecipation))\n",
    "    g.add((R_partecipation, FO['hasNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasGrid'], Literal(row['grid'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasPositionText'], Literal(row['positionTest'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasPositionOrder'], Literal(row['positionOrder'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasPoints'], Literal(row['points'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasLaps'], Literal(row['laps'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasTime'], Literal(row['time'], datatype=XSD.time)))\n",
    "    g.add((R_partecipation, FO['hasMilliseconds'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasFastestLap'], Literal(row['fastestLap'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasFastestLapRank'], Literal(row['rank'], datatype=XSD.integer)))\n",
    "    g.add((R_partecipation, FO['hasFastestLapTime'], Literal(row['fastestLapTime'], datatype=XSD.time)))\n",
    "    g.add((R_partecipation, FO['hasFastestLapSpeed'], Literal(row['fastestLapSpeed'], datatype=XSD.integer)))\n",
    "    \n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    g.add((R_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    Constructor = URIRef(FO[\"constructor\"+str(row['constructorId'])])\n",
    "    g.add((R_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    g.add((R_partecipation, FO['partecipatedInRace'], Race))\n",
    "    \n",
    "    Status = URIRef(FO[\"status\"+str(row['statusId'])])\n",
    "    g.add((R_partecipation, FO['hasStatus'], Status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'race_partecipations.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2233e44",
   "metadata": {},
   "source": [
    "# Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd044a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "q_partecipations = pd.read_csv(qualifyingUrl, sep=',', index_col='qualifyId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in q_partecipations.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    Q_partecipation = URIRef(FO[\"q_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Q_partecipation, RDF.type, FO.QualifPartecipation))\n",
    "    g.add((Q_partecipation, FO['hasNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((Q_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    g.add((Q_partecipation, FO['hasQ1Time'], Literal(row['q1'], datatype=XSD.time)))\n",
    "    g.add((Q_partecipation, FO['hasQ2Time'], Literal(row['q2'], datatype=XSD.time)))\n",
    "    g.add((Q_partecipation, FO['hasQ3Time'], Literal(row['q3'], datatype=XSD.time)))\n",
    "    \n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    g.add((Q_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    Constructor = URIRef(FO[\"constructor\"+str(row['constructorId'])])\n",
    "    g.add((Q_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    Qualifying = URIRef(FO[\"qualifying\"+str(row['raceId'])])\n",
    "    g.add((Qualifying, RDF.type, FO.Qualifying))\n",
    "    g.add((Q_partecipation, FO['partecipatedInQualif'], Qualifying))\n",
    "    \n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    g.add((Race, FO['hasA'], Qualifying))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abe1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'qualifying.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ff574",
   "metadata": {},
   "source": [
    "# Sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9271534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "s_partecipations = pd.read_csv(sprint_resultsUrl, sep=',', index_col='resultId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6544469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in s_partecipations.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    S_partecipation = URIRef(FO[\"s_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((S_partecipation, RDF.type, FO.QualifPartecipation))\n",
    "    g.add((S_partecipation, FO['hasNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasGrid'], Literal(row['grid'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPositionText'], Literal(row['positionTest'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPositionOrder'], Literal(row['positionOrder'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPoints'], Literal(row['points'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasLaps'], Literal(row['laps'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasTime'], Literal(row['time'], datatype=XSD.time)))\n",
    "    g.add((S_partecipation, FO['hasMilliseconds'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasFastestLap'], Literal(row['fastestLap'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasFastestLapTime'], Literal(row['fastestLapTime'], datatype=XSD.time)))\n",
    "    \n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    g.add((Q_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    Constructor = URIRef(FO[\"constructor\"+str(row['constructorId'])])\n",
    "    g.add((Q_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    Sprint = URIRef(FO[\"sprint\"+str(row['raceId'])])\n",
    "    g.add((Sprint, RDF.type, FO.Sprint))\n",
    "    g.add((S_partecipation, FO['partecipatedInSprint'], Sprint))\n",
    "    \n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    g.add((Race, FO['hasA'], Sprint))\n",
    "    \n",
    "    Status = URIRef(FO[\"status\"+str(row['statusId'])])\n",
    "    g.add((S_partecipation, FO['hasStatus'], Status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ccaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'sprint.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle').decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
