{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6904cd",
   "metadata": {},
   "source": [
    "## Populate FASTianF1 RDF database\n",
    "\n",
    "This notebook reports the main steps to download CSV files, process them and create an RDF dataset from them accordingly to an ontology.\n",
    "\n",
    "To measure execution time in Jupyter notebooks: <code>pip install ipython-autotime</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b01ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c483ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c483db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATE \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa963",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5543c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "\n",
    "circuitsUrl = path + '\\FASTianF1\\data\\DatasetF1\\circuits.csv'\n",
    "constructor_resultsUrl = path + '\\FASTianF1\\data\\DatasetF1\\constructor_results.csv'\n",
    "constructor_standingsUrl = path + '\\FASTianF1\\data\\DatasetF1\\constructor_standings.csv'\n",
    "constructorsUrl = path + '\\FASTianF1\\data\\DatasetF1\\constructors.csv'\n",
    "driver_standingsUrl = path + '\\FASTianF1\\data\\DatasetF1\\driver_standings.csv'\n",
    "driversUrl = path + '\\FASTianF1\\data\\DatasetF1\\drivers.csv'\n",
    "lap_timesUrl = path + '\\FASTianF1\\data\\DatasetF1\\lap_times.csv'\n",
    "pit_stopsUrl = path + '\\FASTianF1\\data\\DatasetF1\\pit_stops.csv'\n",
    "qualifyingUrl = path + '\\FASTianF1\\data\\DatasetF1\\qualifying.csv'\n",
    "racesUrl = path + '\\FASTianF1\\data\\DatasetF1\\\\races.csv'\n",
    "resultsUrl = path + '\\FASTianF1\\data\\DatasetF1\\\\results.csv'\n",
    "sprint_resultsUrl = path + '\\FASTianF1\\data\\DatasetF1\\sprint_results.csv'\n",
    "statusUrl = path + '\\FASTianF1\\data\\DatasetF1\\status.csv'\n",
    "ratingsUrl = path + '\\FASTianF1\\data\\DatasetF1\\\\ratings.csv'\n",
    "\n",
    "# country codes and nationalities conversion\n",
    "countriesURL = path + '\\FASTianF1\\data\\countryCodes\\wikipedia-iso-country-codes.csv'\n",
    "nationalitiesURL = path + '\\FASTianF1\\data\\countryCodes\\\\nationalities.csv'\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '\\FASTianF1\\data\\\\rdf\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e71b5",
   "metadata": {},
   "source": [
    "# Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf08a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the movie ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "FO = Namespace(\"https://www.dei.unipd.it/db2/groupProject/FASTianF1#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7880d54",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf231c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the country codes\n",
    "# we need to convert NaN values to something else otherwise NA strings are converted to NaN -> problem with Namibia\n",
    "countries = pd.read_csv(countriesURL, sep=',', index_col='English short name lower case', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8b325",
   "metadata": {},
   "source": [
    "# Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a236e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "drivers = pd.read_csv(driversUrl, sep=',', index_col='driverId')\n",
    "nationalities = pd.read_csv(nationalitiesURL, sep=',', index_col='num_code')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "965c1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077e008d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.03 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the drivers dataframe\n",
    "for index, row in drivers.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"driver\" + the driver id as URI\n",
    "    Driver = URIRef(FO[\"driver\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Driver, RDF.type, FO.Driver))\n",
    "    g.add((Driver, FO['hasDriverRef'], Literal(row['driverRef'], datatype=XSD.string)))\n",
    "    if(str(row['number']) != '\\\\N'):\n",
    "        g.add((Driver, FO['hasDriverNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    if(str(row['code']) != '\\\\N'):\n",
    "        g.add((Driver, FO['hasCode'], Literal(row['code'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasForename'], Literal(row['forename'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasSurname'], Literal(row['surname'], datatype=XSD.string)))\n",
    "    g.add((Driver, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "    \n",
    "    #Check that the date has the year-month-day format otherwise print error\n",
    "    try:\n",
    "        datetime.datetime.strptime(str(row['dob']), '%Y-%m-%d')\n",
    "        g.add((Driver, FO['hasDateOfBirth'], Literal(row['dob'], datatype=XSD.date)))\n",
    "    except ValueError:\n",
    "        print(\"Incorrect date format\")\n",
    "\n",
    "    ## handle nationality\n",
    "    # there can be more than one nationality per driver\n",
    "    for nationality in str(row['nationality']).split('-'):\n",
    "        nationalityName = nationality.strip()\n",
    "        # check if the nationality exists in the nationalities dataframe\n",
    "        # str.contains() returns an array of booleans, thus we need to use the any() method\n",
    "        if((nationalities['nationality'].str.contains(nationalityName, case=False)).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology\n",
    "            #There are multiple countries that correspond to American nationality, then the code for Americans is manually set to \"us\"\n",
    "            if(nationalityName != \"American\"):\n",
    "                code = str(nationalities[nationalities['nationality'].str.contains(nationalityName, case=False)]['alpha_2_code'].values[0]).lower()\n",
    "            else:\n",
    "                code = \"us\"\n",
    "            # create the RDF node for Country\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Driver and the Country \n",
    "            g.add((Driver, FO['hasNation'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff9af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 703 ms\n",
      "Wall time: 697 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'drivers.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa815a7",
   "metadata": {},
   "source": [
    "# Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e32881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "circuits = pd.read_csv(circuitsUrl, sep=',', index_col='circuitId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026c7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d99e3dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "substitutions = {'ó': 'o', 'ü': 'u', 'ã': 'a', ' ': ''}\n",
    "substitutions2 = {'UAE': 'United Arab Emirates', 'USA': 'United States', 'UK': 'United Kingdom', 'Russia': 'Russian Federation', 'Korea': 'Korea, Republic of'}\n",
    "\n",
    "#iterate over the circuits dataframe\n",
    "for index, row in circuits.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"circuits\" + the circuit id as URI\n",
    "    Circuit = URIRef(FO[\"circuit\"+str(index)])\n",
    "    loc = str(row['location'])\n",
    "    # substitution of special characters with standard characters\n",
    "    # special characters are not allowed in URIs\n",
    "    for old, new in substitutions.items():\n",
    "        loc = loc.replace(old, new)\n",
    "    # create the RDF node for location\n",
    "    Location = URIRef(FO[\"location\"+loc])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Location, RDF.type, FO.Location))\n",
    "    g.add((Circuit, RDF.type, FO.Circuit))\n",
    "    g.add((Circuit, FO['hasCircuitRef'], Literal(row['circuitRef'], datatype=XSD.string)))\n",
    "    g.add((Circuit, FO['hasName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Circuit, FO['hasLat'], Literal(row['lat'], datatype=XSD.float)))\n",
    "    g.add((Circuit, FO['hasLng'], Literal(row['lng'], datatype=XSD.float)))\n",
    "    if(str(row['alt']) != '\\\\N'):\n",
    "        g.add((Circuit, FO['hasAlt'], Literal(row['alt'], datatype=XSD.float)))\n",
    "    g.add((Circuit, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "    # add the edge connecting the Circuit and the Location \n",
    "    g.add((Circuit, FO['hasLocation'], Location))\n",
    "\n",
    "    ## handle country\n",
    "    countryName = str(row['country'])\n",
    "    # substitution of abbreviations in country names for full names\n",
    "    for old, new in substitutions2.items():\n",
    "        countryName = countryName.replace(old, new)\n",
    "    # check if the country exists\n",
    "    # str.contains() returns an array of booleans, thus we need to use the any() method\n",
    "    if((countries.index == countryName).any() == True):\n",
    "        #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "        code = str(countries[countries.index == countryName]['Alpha-2 code'][0]).lower()\n",
    "        # create the RDF node for Country\n",
    "        Country = URIRef(CNS[code])\n",
    "        # add the edge connecting the Location and the Country \n",
    "        g.add((Location, FO['hasCountry'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e8fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 84.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'circuits.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab133277",
   "metadata": {},
   "source": [
    "# Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6908695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "constructors = pd.read_csv(constructorsUrl, sep=',', index_col='constructorId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c69926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8612dfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 431 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the constructors dataframe\n",
    "for index, row in constructors.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"constructor\" + the constructor id as URI\n",
    "    Constructor = URIRef(FO[\"constructor\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Constructor, RDF.type, FO.Constructor))\n",
    "    g.add((Constructor, FO['hasConstructorRef'], Literal(row['constructorRef'], datatype=XSD.string)))\n",
    "    g.add((Constructor, FO['hasName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Constructor, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "\n",
    "    ## handle nationality\n",
    "    #there can be more than one nationality per constructor\n",
    "    for nationality in str(row['nationality']).split('-'):\n",
    "        nationalityName = nationality.strip()\n",
    "        # check if the nationality exists\n",
    "        # str.contains() returns an array of booleans, thus we need to use the any() method\n",
    "        if((nationalities['nationality'].str.contains(nationalityName, case=False)).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "            #There are multiple countries that correspond to American nationality, then the code for Americans is manually set to \"us\"\n",
    "            if(nationalityName != \"American\"):\n",
    "                code = str(nationalities[nationalities['nationality'].str.contains(nationalityName, case=False)]['alpha_2_code'].values[0]).lower()\n",
    "            else:\n",
    "                code = \"us\"\n",
    "            # create the RDF node for country\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Constructor and the Country \n",
    "            g.add((Constructor, FO['hasNation'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59913aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'constructors.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577738ca",
   "metadata": {},
   "source": [
    "# Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c60ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "status = pd.read_csv(statusUrl, sep=',', index_col='statusId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74ff8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c386e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 51.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the status dataframe\n",
    "for index, row in status.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"status\" + the status id as URI\n",
    "    Status = URIRef(FO[\"status\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Status, RDF.type, FO.Status))\n",
    "    g.add((Status, FO['hasName'], Literal(row['status'], datatype=XSD.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34df99ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 59.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'status.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dcd70b",
   "metadata": {},
   "source": [
    "# Race (and season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e22c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "races = pd.read_csv(racesUrl, sep=',', index_col='raceId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "687a35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "340c39af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.02 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the races dataframe\n",
    "for index, row in races.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"race\" + the race id as URI\n",
    "    Race = URIRef(FO[\"race\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Race, RDF.type, FO.Race))\n",
    "    g.add((Race, FO['hasRound'], Literal(row['round'], datatype=XSD.integer)))\n",
    "    g.add((Race, FO['hasName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Race, FO['hasDate'], Literal(row['date'], datatype=XSD.date)))\n",
    "    if(str(row['time']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasRaceTime'], Literal(row['time'], datatype=XSD.time)))\n",
    "    g.add((Race, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "    \n",
    "    if(str(row['fp1_date']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp1Date'], Literal(row['fp1_date'], datatype=XSD.date)))\n",
    "    if(str(row['fp1_time']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp1Time'], Literal(row['fp1_time'], datatype=XSD.time)))\n",
    "    if(str(row['fp2_date']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp2Date'], Literal(row['fp2_date'], datatype=XSD.date)))\n",
    "    if(str(row['fp2_time']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp2Time'], Literal(row['fp2_time'], datatype=XSD.time)))\n",
    "    if(str(row['fp3_date']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp3Date'], Literal(row['fp3_date'], datatype=XSD.date)))\n",
    "    if(str(row['fp3_time']) != '\\\\N'):\n",
    "        g.add((Race, FO['hasFp3Time'], Literal(row['fp3_time'], datatype=XSD.time)))\n",
    "    \n",
    "    # create the RDF node for circuit\n",
    "    Circuit = URIRef(FO[\"circuit\"+str(row['circuitId'])])\n",
    "    # add the edge connecting the Race and the Circuit \n",
    "    g.add((Race, FO['hasCircuit'], Circuit))\n",
    "    \n",
    "    # create the RDF node for season\n",
    "    Season = URIRef(FO[\"season\"+str(row['year'])])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Season, RDF.type, FO.Season))\n",
    "    g.add((Season, FO['hasYear'], Literal(row['year'], datatype=XSD.integer)))\n",
    "    g.add((Season, FO['hasURL'], Literal(row['url'], datatype=XSD.string)))\n",
    "    # add the edge connecting the Race and the Season \n",
    "    g.add((Race, FO['inSeason'], Season))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07d2285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 1.14 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'race.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f27d02",
   "metadata": {},
   "source": [
    "# Race (partecipations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5804573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "r_partecipations = pd.read_csv(resultsUrl, sep=',', index_col='resultId')\n",
    "driver_standings = pd.read_csv(driver_standingsUrl, sep=',', index_col=\"driverStandingsId\")\n",
    "constructor_standings = pd.read_csv(constructor_standingsUrl, sep=',', index_col=\"constructorStandingsId\")\n",
    "constructor_results = pd.read_csv(constructor_resultsUrl, sep=',', index_col=\"constructorResultsId\")\n",
    "# join is a dataframe containing the outer join of participation results (r_partecipations) \n",
    "# and driver results (driver_standings)\n",
    "# raceId and driverId are used as join keys\n",
    "join = r_partecipations.merge(driver_standings, how='outer', on=['raceId','driverId'], suffixes=('', 'Total')).fillna('\\\\N')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf33c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85ae2206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "POSITION--> 1 FIRST TIME--> 1:34:50.616\n",
      "1\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 2 FIRST TIME--> 1900-01-01 01:34:50.616000 DELTA--> 0:00:05.478000 NEW TIME--> 01:34:56.094\n",
      "2\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 3 FIRST TIME--> 1900-01-01 01:34:50.616000 DELTA--> 0:00:08.163000 NEW TIME--> 01:34:58.779\n",
      "3\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 4 FIRST TIME--> 1900-01-01 01:34:50.616000 DELTA--> 0:00:17.181000 NEW TIME--> 01:35:07.797\n",
      "4\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 5 FIRST TIME--> 1900-01-01 01:34:50.616000 DELTA--> 0:00:18.014000 NEW TIME--> 01:35:08.630\n",
      "22\n",
      "POSITION--> 1 FIRST TIME--> 1:31:18.555\n",
      "23\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 2 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:00:19.570000 NEW TIME--> 01:31:38.125\n",
      "24\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 3 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:00:38.450000 NEW TIME--> 01:31:57.005\n",
      "25\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 4 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:00:45.832000 NEW TIME--> 01:32:04.387\n",
      "26\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 5 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:00:46.548000 NEW TIME--> 01:32:05.103\n",
      "27\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 6 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:00:49.833000 NEW TIME--> 01:32:08.388\n",
      "28\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 7 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:01:08.130000 NEW TIME--> 01:32:26.685\n",
      "29\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 8 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:01:10.041000 NEW TIME--> 01:32:28.596\n",
      "30\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 9 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:01:16.220000 NEW TIME--> 01:32:34.775\n",
      "31\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 10 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:01:26.214000 NEW TIME--> 01:32:44.769\n",
      "32\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 11 FIRST TIME--> 1900-01-01 01:31:18.555000 DELTA--> 0:01:32.202000 NEW TIME--> 01:32:50.757\n",
      "44\n",
      "POSITION--> 1 FIRST TIME--> 1:31:06.970\n",
      "45\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 2 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:03.339000 NEW TIME--> 01:31:10.309\n",
      "46\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 3 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:04.998000 NEW TIME--> 01:31:11.968\n",
      "47\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 4 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:08.409000 NEW TIME--> 01:31:15.379\n",
      "48\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 5 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:26.789000 NEW TIME--> 01:31:33.759\n",
      "49\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 6 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:41.314000 NEW TIME--> 01:31:48.284\n",
      "50\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 7 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:45.473000 NEW TIME--> 01:31:52.443\n",
      "51\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 8 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:00:55.889000 NEW TIME--> 01:32:02.859\n",
      "52\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 9 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:01:09.500000 NEW TIME--> 01:32:16.470\n",
      "53\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 10 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:01:17.181000 NEW TIME--> 01:32:24.151\n",
      "54\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 11 FIRST TIME--> 1900-01-01 01:31:06.970000 DELTA--> 0:01:17.862000 NEW TIME--> 01:32:24.832\n",
      "66\n",
      "POSITION--> 1 FIRST TIME--> 1:38:19.051\n",
      "67\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 2 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:03.228000 NEW TIME--> 01:38:22.279\n",
      "68\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 3 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:04.187000 NEW TIME--> 01:38:23.238\n",
      "69\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 4 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:05.694000 NEW TIME--> 01:38:24.745\n",
      "70\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 5 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:35.938000 NEW TIME--> 01:38:54.989\n",
      "71\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 6 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:53.010000 NEW TIME--> 01:39:12.061\n",
      "72\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 7 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:58.244000 NEW TIME--> 01:39:17.295\n",
      "73\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 8 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:00:59.435000 NEW TIME--> 01:39:18.486\n",
      "74\n",
      "START FIRST\n",
      "START DELTA\n",
      "POSITION--> 9 FIRST TIME--> 1900-01-01 01:38:19.051000 DELTA--> 0:01:03.073000 NEW TIME--> 01:39:22.124\n",
      "88\n",
      "89\n",
      "START FIRST\n",
      "START DELTA\n",
      "90\n",
      "START FIRST\n",
      "START DELTA\n",
      "91\n",
      "START FIRST\n",
      "START DELTA\n",
      "92\n",
      "START FIRST\n",
      "START DELTA\n",
      "93\n",
      "START FIRST\n",
      "START DELTA\n",
      "94\n",
      "START FIRST\n",
      "START DELTA\n",
      "95\n",
      "START FIRST\n",
      "START DELTA\n",
      "96\n",
      "START FIRST\n",
      "START DELTA\n",
      "97\n",
      "START FIRST\n",
      "START DELTA\n",
      "108\n",
      "109\n",
      "START FIRST\n",
      "START DELTA\n",
      "110\n",
      "START FIRST\n",
      "START DELTA\n",
      "111\n",
      "START FIRST\n",
      "START DELTA\n",
      "112\n",
      "START FIRST\n",
      "START DELTA\n",
      "113\n",
      "START FIRST\n",
      "START DELTA\n",
      "114\n",
      "START FIRST\n",
      "START DELTA\n",
      "115\n",
      "START FIRST\n",
      "START DELTA\n",
      "116\n",
      "START FIRST\n",
      "START DELTA\n",
      "128\n",
      "129\n",
      "START FIRST\n",
      "START DELTA\n",
      "130\n",
      "START FIRST\n",
      "START DELTA\n",
      "131\n",
      "START FIRST\n",
      "START DELTA\n",
      "132\n",
      "START FIRST\n",
      "START DELTA\n",
      "133\n",
      "START FIRST\n",
      "START DELTA\n",
      "134\n",
      "START FIRST\n",
      "START DELTA\n",
      "135\n",
      "START FIRST\n",
      "START DELTA\n",
      "136\n",
      "START FIRST\n",
      "START DELTA\n",
      "137\n",
      "START FIRST\n",
      "START DELTA\n",
      "138\n",
      "START FIRST\n",
      "START DELTA\n",
      "139\n",
      "START FIRST\n",
      "START DELTA\n",
      "148\n",
      "149\n",
      "START FIRST\n",
      "START DELTA\n",
      "150\n",
      "START FIRST\n",
      "START DELTA\n",
      "151\n",
      "START FIRST\n",
      "START DELTA\n",
      "152\n",
      "START FIRST\n",
      "START DELTA\n",
      "153\n",
      "START FIRST\n",
      "START DELTA\n",
      "154\n",
      "START FIRST\n",
      "START DELTA\n",
      "155\n",
      "START FIRST\n",
      "START DELTA\n",
      "156\n",
      "START FIRST\n",
      "START DELTA\n",
      "157\n",
      "START FIRST\n",
      "START DELTA\n",
      "158\n",
      "START FIRST\n",
      "START DELTA\n",
      "159\n",
      "START FIRST\n",
      "START DELTA\n",
      "160\n",
      "START FIRST\n",
      "START DELTA\n",
      "168\n",
      "169\n",
      "START FIRST\n",
      "START DELTA\n",
      "170\n",
      "START FIRST\n",
      "START DELTA\n",
      "188\n",
      "189\n",
      "START FIRST\n",
      "START DELTA\n",
      "190\n",
      "START FIRST\n",
      "START DELTA\n",
      "191\n",
      "START FIRST\n",
      "START DELTA\n",
      "192\n",
      "START FIRST\n",
      "START DELTA\n",
      "193\n",
      "START FIRST\n",
      "START DELTA\n",
      "194\n",
      "START FIRST\n",
      "START DELTA\n",
      "195\n",
      "START FIRST\n",
      "START DELTA\n",
      "196\n",
      "START FIRST\n",
      "START DELTA\n",
      "197\n",
      "START FIRST\n",
      "START DELTA\n",
      "198\n",
      "START FIRST\n",
      "START DELTA\n",
      "199\n",
      "START FIRST\n",
      "START DELTA\n",
      "200\n",
      "START FIRST\n",
      "START DELTA\n",
      "201\n",
      "START FIRST\n",
      "START DELTA\n",
      "202\n",
      "START FIRST\n",
      "START DELTA\n",
      "203\n",
      "START FIRST\n",
      "START DELTA\n",
      "208\n",
      "209\n",
      "START FIRST\n",
      "START DELTA\n",
      "210\n",
      "START FIRST\n",
      "START DELTA\n",
      "211\n",
      "START FIRST\n",
      "START DELTA\n",
      "212\n",
      "START FIRST\n",
      "START DELTA\n",
      "213\n",
      "START FIRST\n",
      "START DELTA\n",
      "214\n",
      "START FIRST\n",
      "START DELTA\n",
      "215\n",
      "START FIRST\n",
      "START DELTA\n",
      "216\n",
      "START FIRST\n",
      "START DELTA\n",
      "217\n",
      "START FIRST\n",
      "START DELTA\n",
      "218\n",
      "START FIRST\n",
      "START DELTA\n",
      "228\n",
      "229\n",
      "START FIRST\n",
      "START DELTA\n",
      "230\n",
      "START FIRST\n",
      "START DELTA\n",
      "231\n",
      "START FIRST\n",
      "START DELTA\n",
      "232\n",
      "START FIRST\n",
      "START DELTA\n",
      "233\n",
      "START FIRST\n",
      "START DELTA\n",
      "234\n",
      "START FIRST\n",
      "START DELTA\n",
      "235\n",
      "START FIRST\n",
      "START DELTA\n",
      "236\n",
      "START FIRST\n",
      "START DELTA\n",
      "237\n",
      "START FIRST\n",
      "START DELTA\n",
      "238\n",
      "START FIRST\n",
      "START DELTA\n",
      "248\n",
      "249\n",
      "START FIRST\n",
      "START DELTA\n",
      "250\n",
      "START FIRST\n",
      "START DELTA\n",
      "251\n",
      "START FIRST\n",
      "START DELTA\n",
      "252\n",
      "START FIRST\n",
      "START DELTA\n",
      "253\n",
      "START FIRST\n",
      "START DELTA\n",
      "254\n",
      "START FIRST\n",
      "START DELTA\n",
      "255\n",
      "START FIRST\n",
      "START DELTA\n",
      "256\n",
      "START FIRST\n",
      "START DELTA\n",
      "268\n",
      "269\n",
      "START FIRST\n",
      "START DELTA\n",
      "270\n",
      "START FIRST\n",
      "START DELTA\n",
      "271\n",
      "START FIRST\n",
      "START DELTA\n",
      "272\n",
      "START FIRST\n",
      "START DELTA\n",
      "273\n",
      "START FIRST\n",
      "START DELTA\n",
      "274\n",
      "START FIRST\n",
      "START DELTA\n",
      "275\n",
      "START FIRST\n",
      "START DELTA\n",
      "276\n",
      "START FIRST\n",
      "START DELTA\n",
      "277\n",
      "START FIRST\n",
      "START DELTA\n",
      "278\n",
      "START FIRST\n",
      "START DELTA\n",
      "279\n",
      "START FIRST\n",
      "START DELTA\n",
      "280\n",
      "START FIRST\n",
      "START DELTA\n",
      "281\n",
      "START FIRST\n",
      "START DELTA\n",
      "282\n",
      "START FIRST\n",
      "START DELTA\n",
      "288\n",
      "289\n",
      "START FIRST\n",
      "START DELTA\n",
      "290\n",
      "START FIRST\n",
      "START DELTA\n",
      "291\n",
      "START FIRST\n",
      "START DELTA\n",
      "292\n",
      "START FIRST\n",
      "START DELTA\n",
      "293\n",
      "START FIRST\n",
      "START DELTA\n",
      "294\n",
      "START FIRST\n",
      "START DELTA\n",
      "295\n",
      "START FIRST\n",
      "START DELTA\n",
      "296\n",
      "START FIRST\n",
      "START DELTA\n",
      "297\n",
      "START FIRST\n",
      "START DELTA\n",
      "298\n",
      "START FIRST\n",
      "START DELTA\n",
      "299\n",
      "START FIRST\n",
      "START DELTA\n",
      "300\n",
      "START FIRST\n",
      "START DELTA\n",
      "301\n",
      "START FIRST\n",
      "START DELTA\n",
      "308\n",
      "309\n",
      "START FIRST\n",
      "START DELTA\n",
      "310\n",
      "START FIRST\n",
      "START DELTA\n",
      "311\n",
      "START FIRST\n",
      "START DELTA\n",
      "312\n",
      "START FIRST\n",
      "START DELTA\n",
      "313\n",
      "START FIRST\n",
      "START DELTA\n",
      "314\n",
      "START FIRST\n",
      "START DELTA\n",
      "315\n",
      "START FIRST\n",
      "START DELTA\n",
      "316\n",
      "START FIRST\n",
      "START DELTA\n",
      "317\n",
      "START FIRST\n",
      "START DELTA\n",
      "318\n",
      "START FIRST\n",
      "START DELTA\n",
      "319\n",
      "START FIRST\n",
      "START DELTA\n",
      "328\n",
      "329\n",
      "START FIRST\n",
      "START DELTA\n",
      "330\n",
      "START FIRST\n",
      "START DELTA\n",
      "331\n",
      "START FIRST\n",
      "START DELTA\n",
      "332\n",
      "START FIRST\n",
      "START DELTA\n",
      "333\n",
      "START FIRST\n",
      "START DELTA\n",
      "334\n",
      "START FIRST\n",
      "START DELTA\n",
      "335\n",
      "START FIRST\n",
      "START DELTA\n",
      "336\n",
      "START FIRST\n",
      "START DELTA\n",
      "337\n",
      "START FIRST\n",
      "START DELTA\n",
      "338\n",
      "START FIRST\n",
      "START DELTA\n",
      "339\n",
      "START FIRST\n",
      "START DELTA\n",
      "340\n",
      "START FIRST\n",
      "START DELTA\n",
      "341\n",
      "START FIRST\n",
      "START DELTA\n",
      "348\n",
      "349\n",
      "START FIRST\n",
      "START DELTA\n",
      "350\n",
      "START FIRST\n",
      "START DELTA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "START FIRST\n",
      "START DELTA\n",
      "352\n",
      "START FIRST\n",
      "START DELTA\n",
      "353\n",
      "START FIRST\n",
      "START DELTA\n",
      "354\n",
      "START FIRST\n",
      "START DELTA\n",
      "355\n",
      "START FIRST\n",
      "START DELTA\n",
      "356\n",
      "START FIRST\n",
      "START DELTA\n",
      "368\n",
      "369\n",
      "START FIRST\n",
      "START DELTA\n",
      "370\n",
      "START FIRST\n",
      "START DELTA\n",
      "371\n",
      "START FIRST\n",
      "START DELTA\n",
      "372\n",
      "START FIRST\n",
      "START DELTA\n",
      "373\n",
      "START FIRST\n",
      "START DELTA\n",
      "390\n",
      "391\n",
      "START FIRST\n",
      "START DELTA\n",
      "392\n",
      "START FIRST\n",
      "START DELTA\n",
      "393\n",
      "START FIRST\n",
      "START DELTA\n",
      "394\n",
      "START FIRST\n",
      "START DELTA\n",
      "395\n",
      "START FIRST\n",
      "START DELTA\n",
      "396\n",
      "START FIRST\n",
      "START DELTA\n",
      "397\n",
      "START FIRST\n",
      "START DELTA\n",
      "398\n",
      "START FIRST\n",
      "START DELTA\n",
      "399\n",
      "START FIRST\n",
      "START DELTA\n",
      "412\n",
      "413\n",
      "START FIRST\n",
      "START DELTA\n",
      "414\n",
      "START FIRST\n",
      "START DELTA\n",
      "415\n",
      "START FIRST\n",
      "START DELTA\n",
      "416\n",
      "START FIRST\n",
      "START DELTA\n",
      "417\n",
      "START FIRST\n",
      "START DELTA\n",
      "418\n",
      "START FIRST\n",
      "START DELTA\n",
      "419\n",
      "START FIRST\n",
      "START DELTA\n",
      "420\n",
      "START FIRST\n",
      "START DELTA\n",
      "421\n",
      "START FIRST\n",
      "START DELTA\n",
      "434\n",
      "435\n",
      "START FIRST\n",
      "START DELTA\n",
      "436\n",
      "START FIRST\n",
      "START DELTA\n",
      "437\n",
      "START FIRST\n",
      "START DELTA\n",
      "438\n",
      "START FIRST\n",
      "START DELTA\n",
      "439\n",
      "START FIRST\n",
      "START DELTA\n",
      "440\n",
      "START FIRST\n",
      "START DELTA\n",
      "456\n",
      "457\n",
      "START FIRST\n",
      "START DELTA\n",
      "458\n",
      "START FIRST\n",
      "START DELTA\n",
      "478\n",
      "479\n",
      "START FIRST\n",
      "START DELTA\n",
      "480\n",
      "START FIRST\n",
      "START DELTA\n",
      "481\n",
      "START FIRST\n",
      "START DELTA\n",
      "482\n",
      "START FIRST\n",
      "START DELTA\n",
      "483\n",
      "START FIRST\n",
      "START DELTA\n",
      "484\n",
      "START FIRST\n",
      "START DELTA\n",
      "485\n",
      "START FIRST\n",
      "START DELTA\n",
      "486\n",
      "START FIRST\n",
      "START DELTA\n",
      "487\n",
      "START FIRST\n",
      "START DELTA\n",
      "488\n",
      "START FIRST\n",
      "START DELTA\n",
      "489\n",
      "START FIRST\n",
      "START DELTA\n",
      "500\n",
      "501\n",
      "START FIRST\n",
      "START DELTA\n",
      "502\n",
      "START FIRST\n",
      "START DELTA\n",
      "503\n",
      "START FIRST\n",
      "START DELTA\n",
      "504\n",
      "START FIRST\n",
      "START DELTA\n",
      "505\n",
      "START FIRST\n",
      "START DELTA\n",
      "506\n",
      "START FIRST\n",
      "START DELTA\n",
      "507\n",
      "START FIRST\n",
      "START DELTA\n",
      "522\n",
      "523\n",
      "START FIRST\n",
      "START DELTA\n",
      "524\n",
      "START FIRST\n",
      "START DELTA\n",
      "525\n",
      "START FIRST\n",
      "START DELTA\n",
      "526\n",
      "START FIRST\n",
      "START DELTA\n",
      "527\n",
      "START FIRST\n",
      "START DELTA\n",
      "528\n",
      "START FIRST\n",
      "START DELTA\n",
      "529\n",
      "START FIRST\n",
      "START DELTA\n",
      "530\n",
      "START FIRST\n",
      "START DELTA\n",
      "544\n",
      "545\n",
      "START FIRST\n",
      "START DELTA\n",
      "546\n",
      "START FIRST\n",
      "START DELTA\n",
      "547\n",
      "START FIRST\n",
      "START DELTA\n",
      "548\n",
      "START FIRST\n",
      "START DELTA\n",
      "549\n",
      "START FIRST\n",
      "START DELTA\n",
      "566\n",
      "567\n",
      "START FIRST\n",
      "START DELTA\n",
      "568\n",
      "START FIRST\n",
      "START DELTA\n",
      "569\n",
      "START FIRST\n",
      "START DELTA\n",
      "570\n",
      "START FIRST\n",
      "START DELTA\n",
      "571\n",
      "START FIRST\n",
      "START DELTA\n",
      "572\n",
      "START FIRST\n",
      "START DELTA\n",
      "588\n",
      "589\n",
      "START FIRST\n",
      "START DELTA\n",
      "590\n",
      "START FIRST\n",
      "START DELTA\n",
      "591\n",
      "START FIRST\n",
      "START DELTA\n",
      "592\n",
      "START FIRST\n",
      "START DELTA\n",
      "593\n",
      "START FIRST\n",
      "START DELTA\n",
      "594\n",
      "START FIRST\n",
      "START DELTA\n",
      "595\n",
      "START FIRST\n",
      "START DELTA\n",
      "596\n",
      "START FIRST\n",
      "START DELTA\n",
      "610\n",
      "611\n",
      "START FIRST\n",
      "START DELTA\n",
      "612\n",
      "START FIRST\n",
      "START DELTA\n",
      "613\n",
      "START FIRST\n",
      "START DELTA\n",
      "614\n",
      "START FIRST\n",
      "START DELTA\n",
      "615\n",
      "START FIRST\n",
      "START DELTA\n",
      "616\n",
      "START FIRST\n",
      "START DELTA\n",
      "617\n",
      "START FIRST\n",
      "START DELTA\n",
      "618\n",
      "START FIRST\n",
      "START DELTA\n",
      "619\n",
      "START FIRST\n",
      "START DELTA\n",
      "620\n",
      "START FIRST\n",
      "START DELTA\n",
      "632\n",
      "633\n",
      "START FIRST\n",
      "START DELTA\n",
      "634\n",
      "START FIRST\n",
      "START DELTA\n",
      "635\n",
      "START FIRST\n",
      "START DELTA\n",
      "636\n",
      "START FIRST\n",
      "START DELTA\n",
      "637\n",
      "START FIRST\n",
      "START DELTA\n",
      "638\n",
      "START FIRST\n",
      "START DELTA\n",
      "639\n",
      "START FIRST\n",
      "START DELTA\n",
      "640\n",
      "START FIRST\n",
      "START DELTA\n",
      "641\n",
      "START FIRST\n",
      "START DELTA\n",
      "642\n",
      "START FIRST\n",
      "START DELTA\n",
      "654\n",
      "655\n",
      "START FIRST\n",
      "START DELTA\n",
      "656\n",
      "START FIRST\n",
      "START DELTA\n",
      "657\n",
      "START FIRST\n",
      "START DELTA\n",
      "658\n",
      "START FIRST\n",
      "START DELTA\n",
      "659\n",
      "START FIRST\n",
      "START DELTA\n",
      "660\n",
      "START FIRST\n",
      "START DELTA\n",
      "661\n",
      "START FIRST\n",
      "START DELTA\n",
      "662\n",
      "START FIRST\n",
      "START DELTA\n",
      "663\n",
      "START FIRST\n",
      "START DELTA\n",
      "664\n",
      "START FIRST\n",
      "START DELTA\n",
      "676\n",
      "677\n",
      "START FIRST\n",
      "START DELTA\n",
      "678\n",
      "START FIRST\n",
      "START DELTA\n",
      "679\n",
      "START FIRST\n",
      "START DELTA\n",
      "680\n",
      "START FIRST\n",
      "START DELTA\n",
      "681\n",
      "START FIRST\n",
      "START DELTA\n",
      "682\n",
      "START FIRST\n",
      "START DELTA\n",
      "683\n",
      "START FIRST\n",
      "START DELTA\n",
      "684\n",
      "START FIRST\n",
      "START DELTA\n",
      "685\n",
      "START FIRST\n",
      "START DELTA\n",
      "698\n",
      "699\n",
      "START FIRST\n",
      "START DELTA\n",
      "700\n",
      "START FIRST\n",
      "START DELTA\n",
      "701\n",
      "START FIRST\n",
      "START DELTA\n",
      "702\n",
      "START FIRST\n",
      "START DELTA\n",
      "703\n",
      "START FIRST\n",
      "START DELTA\n",
      "704\n",
      "START FIRST\n",
      "START DELTA\n",
      "705\n",
      "START FIRST\n",
      "START DELTA\n",
      "706\n",
      "START FIRST\n",
      "START DELTA\n",
      "707\n",
      "START FIRST\n",
      "START DELTA\n",
      "708\n",
      "START FIRST\n",
      "START DELTA\n",
      "720\n",
      "721\n",
      "START FIRST\n",
      "START DELTA\n",
      "722\n",
      "START FIRST\n",
      "START DELTA\n",
      "723\n",
      "START FIRST\n",
      "START DELTA\n",
      "724\n",
      "START FIRST\n",
      "START DELTA\n",
      "725\n",
      "START FIRST\n",
      "START DELTA\n",
      "742\n",
      "743\n",
      "START FIRST\n",
      "START DELTA\n",
      "744\n",
      "START FIRST\n",
      "START DELTA\n",
      "745\n",
      "START FIRST\n",
      "START DELTA\n",
      "746\n",
      "START FIRST\n",
      "START DELTA\n",
      "747\n",
      "START FIRST\n",
      "START DELTA\n",
      "748\n",
      "START FIRST\n",
      "START DELTA\n",
      "749\n",
      "START FIRST\n",
      "START DELTA\n",
      "750\n",
      "START FIRST\n",
      "START DELTA\n",
      "751\n",
      "START FIRST\n",
      "START DELTA\n",
      "752\n",
      "START FIRST\n",
      "START DELTA\n",
      "764\n",
      "765\n",
      "START FIRST\n",
      "START DELTA\n",
      "766\n",
      "START FIRST\n",
      "START DELTA\n",
      "767\n",
      "START FIRST\n",
      "START DELTA\n",
      "768\n",
      "START FIRST\n",
      "START DELTA\n",
      "769\n",
      "START FIRST\n",
      "START DELTA\n",
      "770\n",
      "START FIRST\n",
      "START DELTA\n",
      "771\n",
      "START FIRST\n",
      "START DELTA\n",
      "786\n",
      "787\n",
      "START FIRST\n",
      "START DELTA\n",
      "788\n",
      "START FIRST\n",
      "START DELTA\n",
      "789\n",
      "START FIRST\n",
      "START DELTA\n",
      "790\n",
      "START FIRST\n",
      "START DELTA\n",
      "791\n",
      "START FIRST\n",
      "START DELTA\n",
      "792\n",
      "START FIRST\n",
      "START DELTA\n",
      "793\n",
      "START FIRST\n",
      "START DELTA\n",
      "794\n",
      "START FIRST\n",
      "START DELTA\n",
      "808\n",
      "809\n",
      "START FIRST\n",
      "START DELTA\n",
      "810\n",
      "START FIRST\n",
      "START DELTA\n",
      "811\n",
      "START FIRST\n",
      "START DELTA\n",
      "812\n",
      "START FIRST\n",
      "START DELTA\n",
      "813\n",
      "START FIRST\n",
      "START DELTA\n",
      "814\n",
      "START FIRST\n",
      "START DELTA\n",
      "815\n",
      "START FIRST\n",
      "START DELTA\n",
      "816\n",
      "START FIRST\n",
      "START DELTA\n",
      "817\n",
      "START FIRST\n",
      "START DELTA\n",
      "818\n",
      "START FIRST\n",
      "START DELTA\n",
      "819\n",
      "START FIRST\n",
      "START DELTA\n",
      "830\n",
      "831\n",
      "START FIRST\n",
      "START DELTA\n",
      "832\n",
      "START FIRST\n",
      "START DELTA\n",
      "833\n",
      "START FIRST\n",
      "START DELTA\n",
      "834\n",
      "START FIRST\n",
      "START DELTA\n",
      "835\n",
      "START FIRST\n",
      "START DELTA\n",
      "836\n",
      "START FIRST\n",
      "START DELTA\n",
      "837\n",
      "START FIRST\n",
      "START DELTA\n",
      "852\n",
      "853\n",
      "START FIRST\n",
      "START DELTA\n",
      "854\n",
      "START FIRST\n",
      "START DELTA\n",
      "855\n",
      "START FIRST\n",
      "START DELTA\n",
      "856\n",
      "START FIRST\n",
      "START DELTA\n",
      "857\n",
      "START FIRST\n",
      "START DELTA\n",
      "874\n",
      "875\n",
      "START FIRST\n",
      "START DELTA\n",
      "876\n",
      "START FIRST\n",
      "START DELTA\n",
      "877\n",
      "START FIRST\n",
      "START DELTA\n",
      "878\n",
      "START FIRST\n",
      "START DELTA\n",
      "879\n",
      "START FIRST\n",
      "START DELTA\n",
      "896\n",
      "897\n",
      "START FIRST\n",
      "START DELTA\n",
      "898\n",
      "START FIRST\n",
      "START DELTA\n",
      "899\n",
      "START FIRST\n",
      "START DELTA\n",
      "900\n",
      "START FIRST\n",
      "START DELTA\n",
      "901\n",
      "START FIRST\n",
      "START DELTA\n",
      "902\n",
      "START FIRST\n",
      "START DELTA\n",
      "903\n",
      "START FIRST\n",
      "START DELTA\n",
      "904\n",
      "START FIRST\n",
      "START DELTA\n",
      "918\n",
      "919\n",
      "START FIRST\n",
      "START DELTA\n",
      "920\n",
      "START FIRST\n",
      "START DELTA\n",
      "921\n",
      "START FIRST\n",
      "START DELTA\n",
      "922\n",
      "START FIRST\n",
      "START DELTA\n",
      "940\n",
      "941\n",
      "START FIRST\n",
      "START DELTA\n",
      "942\n",
      "START FIRST\n",
      "START DELTA\n",
      "943\n",
      "START FIRST\n",
      "START DELTA\n",
      "944\n",
      "START FIRST\n",
      "START DELTA\n",
      "945\n",
      "START FIRST\n",
      "START DELTA\n",
      "962\n",
      "963\n",
      "START FIRST\n",
      "START DELTA\n",
      "964\n",
      "START FIRST\n",
      "START DELTA\n",
      "965\n",
      "START FIRST\n",
      "START DELTA\n",
      "966\n",
      "START FIRST\n",
      "START DELTA\n",
      "967\n",
      "START FIRST\n",
      "START DELTA\n",
      "968\n",
      "START FIRST\n",
      "START DELTA\n",
      "984\n",
      "985\n",
      "START FIRST\n",
      "START DELTA\n",
      "986\n",
      "START FIRST\n",
      "START DELTA\n",
      "987\n",
      "START FIRST\n",
      "START DELTA\n",
      "988\n",
      "START FIRST\n",
      "START DELTA\n",
      "989\n",
      "START FIRST\n",
      "START DELTA\n",
      "990\n",
      "START FIRST\n",
      "START DELTA\n",
      "991\n",
      "START FIRST\n",
      "START DELTA\n",
      "992\n",
      "START FIRST\n",
      "START DELTA\n",
      "1006\n",
      "1007\n",
      "START FIRST\n",
      "START DELTA\n",
      "1008\n",
      "START FIRST\n",
      "START DELTA\n",
      "1009\n",
      "START FIRST\n",
      "START DELTA\n",
      "1028\n",
      "1029\n",
      "START FIRST\n",
      "START DELTA\n",
      "1030\n",
      "START FIRST\n",
      "START DELTA\n",
      "1031\n",
      "START FIRST\n",
      "START DELTA\n",
      "1032\n",
      "START FIRST\n",
      "START DELTA\n",
      "1033\n",
      "START FIRST\n",
      "START DELTA\n",
      "1034\n",
      "START FIRST\n",
      "START DELTA\n",
      "1035\n",
      "START FIRST\n",
      "START DELTA\n",
      "1050\n",
      "1051\n",
      "START FIRST\n",
      "START DELTA\n",
      "1052\n",
      "START FIRST\n",
      "START DELTA\n",
      "1053\n",
      "START FIRST\n",
      "START DELTA\n",
      "1054\n",
      "START FIRST\n",
      "START DELTA\n",
      "1055\n",
      "START FIRST\n",
      "START DELTA\n",
      "1056\n",
      "START FIRST\n",
      "START DELTA\n",
      "1057\n",
      "START FIRST\n",
      "START DELTA\n",
      "1058\n",
      "START FIRST\n",
      "START DELTA\n",
      "1059\n",
      "START FIRST\n",
      "START DELTA\n",
      "1072\n",
      "1073\n",
      "START FIRST\n",
      "START DELTA\n",
      "1074\n",
      "START FIRST\n",
      "START DELTA\n",
      "1075\n",
      "START FIRST\n",
      "START DELTA\n",
      "1076\n",
      "START FIRST\n",
      "START DELTA\n",
      "1077\n",
      "START FIRST\n",
      "START DELTA\n",
      "1078\n",
      "START FIRST\n",
      "START DELTA\n",
      "1079\n",
      "START FIRST\n",
      "START DELTA\n",
      "1080\n",
      "START FIRST\n",
      "START DELTA\n",
      "1094\n",
      "1095\n",
      "START FIRST\n",
      "START DELTA\n",
      "1096\n",
      "START FIRST\n",
      "START DELTA\n",
      "1097\n",
      "START FIRST\n",
      "START DELTA\n",
      "1098\n",
      "START FIRST\n",
      "START DELTA\n",
      "1099\n",
      "START FIRST\n",
      "START DELTA\n",
      "1100\n",
      "START FIRST\n",
      "START DELTA\n",
      "1101\n",
      "START FIRST\n",
      "START DELTA\n",
      "1102\n",
      "START FIRST\n",
      "START DELTA\n",
      "1116\n",
      "1117\n",
      "START FIRST\n",
      "START DELTA\n",
      "1118\n",
      "START FIRST\n",
      "START DELTA\n",
      "1119\n",
      "START FIRST\n",
      "START DELTA\n",
      "1120\n",
      "START FIRST\n",
      "START DELTA\n",
      "1121\n",
      "START FIRST\n",
      "START DELTA\n",
      "1122\n",
      "START FIRST\n",
      "START DELTA\n",
      "1123\n",
      "START FIRST\n",
      "START DELTA\n",
      "1124\n",
      "START FIRST\n",
      "START DELTA\n",
      "1138\n",
      "1139\n",
      "START FIRST\n",
      "START DELTA\n",
      "1140\n",
      "START FIRST\n",
      "START DELTA\n",
      "1141\n",
      "START FIRST\n",
      "START DELTA\n",
      "1142\n",
      "START FIRST\n",
      "START DELTA\n",
      "1143\n",
      "START FIRST\n",
      "START DELTA\n",
      "1144\n",
      "START FIRST\n",
      "START DELTA\n",
      "1145\n",
      "START FIRST\n",
      "START DELTA\n",
      "1146\n",
      "START FIRST\n",
      "START DELTA\n",
      "1147\n",
      "START FIRST\n",
      "START DELTA\n",
      "1158\n",
      "1159\n",
      "START FIRST\n",
      "START DELTA\n",
      "1160\n",
      "START FIRST\n",
      "START DELTA\n",
      "1161\n",
      "START FIRST\n",
      "START DELTA\n",
      "1162\n",
      "START FIRST\n",
      "START DELTA\n",
      "1163\n",
      "START FIRST\n",
      "START DELTA\n",
      "1164\n",
      "START FIRST\n",
      "START DELTA\n",
      "1165\n",
      "START FIRST\n",
      "START DELTA\n",
      "1166\n",
      "START FIRST\n",
      "START DELTA\n",
      "1178\n",
      "1179\n",
      "START FIRST\n",
      "START DELTA\n",
      "1180\n",
      "START FIRST\n",
      "START DELTA\n",
      "1181\n",
      "START FIRST\n",
      "START DELTA\n",
      "1182\n",
      "START FIRST\n",
      "START DELTA\n",
      "1183\n",
      "START FIRST\n",
      "START DELTA\n",
      "1198\n",
      "1199\n",
      "START FIRST\n",
      "START DELTA\n",
      "1200\n",
      "START FIRST\n",
      "START DELTA\n",
      "1201\n",
      "START FIRST\n",
      "START DELTA\n",
      "1202\n",
      "START FIRST\n",
      "START DELTA\n",
      "1203\n",
      "START FIRST\n",
      "START DELTA\n",
      "1204\n",
      "START FIRST\n",
      "START DELTA\n",
      "1205\n",
      "START FIRST\n",
      "START DELTA\n",
      "1206\n",
      "START FIRST\n",
      "START DELTA\n",
      "1216\n",
      "START FIRST\n",
      "START DELTA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217\n",
      "START FIRST\n",
      "START DELTA\n",
      "1218\n",
      "1219\n",
      "START FIRST\n",
      "START DELTA\n",
      "1220\n",
      "START FIRST\n",
      "START DELTA\n",
      "1221\n",
      "START FIRST\n",
      "START DELTA\n",
      "1222\n",
      "START FIRST\n",
      "START DELTA\n",
      "1223\n",
      "START FIRST\n",
      "START DELTA\n",
      "1236\n",
      "1237\n",
      "START FIRST\n",
      "START DELTA\n",
      "1238\n",
      "START FIRST\n",
      "START DELTA\n",
      "1239\n",
      "START FIRST\n",
      "START DELTA\n",
      "1240\n",
      "START FIRST\n",
      "START DELTA\n",
      "1241\n",
      "START FIRST\n",
      "START DELTA\n",
      "1242\n",
      "START FIRST\n",
      "START DELTA\n",
      "1243\n",
      "START FIRST\n",
      "START DELTA\n",
      "1254\n",
      "1255\n",
      "START FIRST\n",
      "START DELTA\n",
      "1256\n",
      "START FIRST\n",
      "START DELTA\n",
      "1257\n",
      "START FIRST\n",
      "START DELTA\n",
      "1258\n",
      "START FIRST\n",
      "START DELTA\n",
      "1259\n",
      "START FIRST\n",
      "START DELTA\n",
      "1260\n",
      "START FIRST\n",
      "START DELTA\n",
      "1261\n",
      "START FIRST\n",
      "START DELTA\n",
      "1262\n",
      "START FIRST\n",
      "START DELTA\n",
      "1263\n",
      "START FIRST\n",
      "START DELTA\n",
      "1274\n",
      "1275\n",
      "START FIRST\n",
      "START DELTA\n",
      "1276\n",
      "START FIRST\n",
      "START DELTA\n",
      "1277\n",
      "START FIRST\n",
      "START DELTA\n",
      "1278\n",
      "START FIRST\n",
      "START DELTA\n",
      "1294\n",
      "1295\n",
      "START FIRST\n",
      "START DELTA\n",
      "1314\n",
      "1315\n",
      "START FIRST\n",
      "START DELTA\n",
      "1316\n",
      "START FIRST\n",
      "START DELTA\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the join dataframe\n",
    "for index, row in join.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"r_partecipation\" + the partecipation id as URI\n",
    "    R_partecipation = URIRef(FO[\"r_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((R_partecipation, RDF.type, FO.RacePartecipation))\n",
    "    if(str(row['number']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasCarNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    if(str(row['grid']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasStartingGridPosition'], Literal(int(row['grid']), datatype=XSD.integer)))\n",
    "    if(str(row['position']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    if(str(row['positionText']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasPositionText'], Literal(row['positionText'], datatype=XSD.string)))\n",
    "    if(str(row['positionOrder']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasPositionOrder'], Literal(int(row['positionOrder']), datatype=XSD.integer)))\n",
    "    if(str(row['points']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasPoints'], Literal(int(row['points']), datatype=XSD.integer)))\n",
    "    if(str(row['laps']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasLaps'], Literal(int(row['laps']), datatype=XSD.integer)))\n",
    "    if(str(row['time']) != '\\\\N'):\n",
    "        #g.add((R_partecipation, FO['hasResultTime'], Literal(row['time'], datatype=XSD.string)))\n",
    "        print(index)\n",
    "        if row['time'][0] == \"+\":\n",
    "            #FIRST_TIME RETRIEVAL\n",
    "            print(\"START FIRST\")\n",
    "            tmp = join[(join['raceId'] == row['raceId']) & (join['positionText'] == '1')]\n",
    "            print(\"Error\") if (tmp.shape[0]!=1) else None\n",
    "            splitted_time = str(tmp.iloc[0]['time']).split('.')\n",
    "            formatted_time = \"00:00:00\"[0:8-len(splitted_time[0])] + splitted_time[0] + \".\" + splitted_time[1].ljust(3,\"0\")\n",
    "            first_time = datetime.datetime.strptime(formatted_time, \"%H:%M:%S.%f\")\n",
    "            #DELTA RETRIEVAL\n",
    "            print(\"START DELTA\")\n",
    "            time = str(row['time']).strip()[1:]\n",
    "            if ':' in (time.split('.')[0]):\n",
    "                time_distance = \"00:00:00.000\"[0:12-len(time)] + time\n",
    "                (h, m, s) = time_distance.split('.')[0].split(':')\n",
    "            else:\n",
    "                time_distance = time\n",
    "                (h, m, s) = (0,0, time_distance.split('.')[0])\n",
    "            d = datetime.timedelta(hours=int(h), minutes=int(m), seconds=int(s), milliseconds=int(time_distance.split('.')[1]))\n",
    "            #FIRST_TIME + DELTA\n",
    "            new_time = first_time + d\n",
    "            g.add((R_partecipation, FO['hasResultTime'], Literal(new_time.strftime(\"%H:%M:%S.%f\")[:12], datatype=XSD.time)))\n",
    "            if(int(row['raceId']) < 22):\n",
    "                print(\"POSITION-->\",str(row['positionText']),\"FIRST TIME-->\",first_time,\"DELTA-->\",d,\"NEW TIME-->\",\n",
    "                      new_time.strftime(\"%H:%M:%S.%f\")[:12])\n",
    "        else:\n",
    "            splitted_time = str(row['time']).split('.')\n",
    "            formatted_time = \"00:00:00\"[0:8-len(splitted_time[0])] + splitted_time[0] + \".\" + splitted_time[1].ljust(3,\"0\")\n",
    "            g.add((R_partecipation, FO['hasResultTime'], Literal(formatted_time, datatype=XSD.time)))\n",
    "            if(int(row['raceId']) < 22):\n",
    "                print(\"POSITION-->\",str(row['positionText']),\"FIRST TIME-->\",str(row['time']))\n",
    "    if(str(row['milliseconds']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasMillisecondsResultTime'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    if(str(row['fastestLap']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasFastestLap'], Literal(row['fastestLap'], datatype=XSD.integer)))\n",
    "    if(str(row['rank']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasFastestLapRank'], Literal(row['rank'], datatype=XSD.integer)))\n",
    "    if(str(row['fastestLapTime']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasFastestLapTime'], Literal(\"00:00:00.000\"[0:12-len(str(row['fastestLapTime']))] + \n",
    "                                                                 str(row['fastestLapTime']), datatype=XSD.time)))\n",
    "    if(str(row['fastestLapSpeed']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasFastestLapSpeed'], Literal(row['fastestLapSpeed'], datatype=XSD.string)))\n",
    "    if(str(row['pointsTotal']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasTotalPoints'], Literal(int(row['pointsTotal']), datatype=XSD.integer)))\n",
    "    if(str(row['positionTotal']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasTotalPosition'], Literal(int(row['positionTotal']), datatype=XSD.integer)))\n",
    "    if(str(row['positionTextTotal']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasTotalPositionText'], Literal(row['positionTextTotal'], datatype=XSD.string)))\n",
    "    if(str(row['wins']) != '\\\\N'):\n",
    "        g.add((R_partecipation, FO['hasDriversWins'], Literal(int(row['wins']), datatype=XSD.integer)))\n",
    "    \n",
    "    # create the RDF node for driver\n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    # add the edge connecting the Partecipation and the Driver \n",
    "    g.add((R_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    if(str(row['constructorId']) != '\\\\N'):\n",
    "        # create the RDF node for constructor\n",
    "        Constructor = URIRef(FO[\"constructor\"+str(int(row['constructorId']))])\n",
    "        # add the edge connecting the Partecipation and the Constructor \n",
    "        g.add((R_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    # create the RDF node for race\n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    # add the edge connecting the Partecipation and the Race \n",
    "    g.add((R_partecipation, FO['partecipatedInRace'], Race))\n",
    "    \n",
    "    if(str(row['statusId']) != '\\\\N'):\n",
    "        # create the RDF node for status\n",
    "        Status = URIRef(FO[\"status\"+str(int(row['statusId']))])\n",
    "        # add the edge connecting the Partecipation and the Status \n",
    "        g.add((R_partecipation, FO['hasStatus'], Status))\n",
    "\n",
    "#iterate over the constructor_standings dataframe\n",
    "for index, row in constructor_standings.iterrows():\n",
    "    # Get the rows of the join dataframe with the raceId and constructorId values matching those in the current row.\n",
    "    tmp = join[(join['raceId'] == row['raceId']) & (join['constructorId'] == row['constructorId'])]\n",
    "    #iterate over the rows found\n",
    "    for index2, row2 in tmp.iterrows():\n",
    "        # create the RDF node for racePartecipation\n",
    "        R_partecipation = URIRef(FO[\"r_partecipation\"+str(index2)])\n",
    "        # Add triples using store's add() method.\n",
    "        g.add((R_partecipation, FO['hasConstructorTotalPoints'], Literal(int(row['points']), datatype=XSD.integer)))\n",
    "        g.add((R_partecipation, FO['hasConstructorTotalPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "        g.add((R_partecipation, FO['hasConstructorTotalPositionText'], Literal(row['positionText'], datatype=XSD.string)))\n",
    "        g.add((R_partecipation, FO['hasConstructorsWins'], Literal(int(row['wins']), datatype=XSD.integer)))\n",
    "\n",
    "#iterate over the constructor_results dataframe\n",
    "for index, row in constructor_results.iterrows():\n",
    "    # Get the rows of the join dataframe with the raceId and constructorId values matching those in the current row.\n",
    "    tmp = join[(join['raceId'] == row['raceId']) & (join['constructorId'] == row['constructorId'])]\n",
    "    #iterate over the rows found\n",
    "    for index2, row2 in tmp.iterrows():\n",
    "        # create the RDF node for racePartecipation\n",
    "        R_partecipation = URIRef(FO[\"r_partecipation\"+str(index2)])\n",
    "        # Add triples using store's add() method.\n",
    "        g.add((R_partecipation, FO['hasConstructorPoints'], Literal(int(row['points']), datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75c2c025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'race_partecipations.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2233e44",
   "metadata": {},
   "source": [
    "# Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd044a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "q_partecipations = pd.read_csv(qualifyingUrl, sep=',', index_col='qualifyId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b3a7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "465d6aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.08 s\n",
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the q_partecipations dataframe\n",
    "for index, row in q_partecipations.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"q_partecipation\" + the qualifying partecipation id as URI\n",
    "    Q_partecipation = URIRef(FO[\"q_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Q_partecipation, RDF.type, FO.QualifPartecipation))\n",
    "    g.add((Q_partecipation, FO['hasCarNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((Q_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    if(str(row['q1']) != '\\\\N'):\n",
    "        g.add((Q_partecipation, FO['hasQ1Time'], Literal(\"00:00:00.000\"[0:12-len(str(row['q1']))] + \n",
    "                                                         str(row['q1']), datatype=XSD.time)))\n",
    "    if(str(row['q2']) != '\\\\N'):\n",
    "        g.add((Q_partecipation, FO['hasQ2Time'], Literal(\"00:00:00.000\"[0:12-len(str(row['q2']))] + \n",
    "                                                         str(row['q2']), datatype=XSD.time)))\n",
    "    if(str(row['q3']) != '\\\\N'):\n",
    "        g.add((Q_partecipation, FO['hasQ3Time'], Literal(\"00:00:00.000\"[0:12-len(str(row['q3']))] + \n",
    "                                                         str(row['q3']), datatype=XSD.time)))\n",
    "\n",
    "    # create the RDF node for driver\n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    # add the edge connecting the qualifyingPartecipation and the Driver \n",
    "    g.add((Q_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    # create the RDF node for constructor\n",
    "    Constructor = URIRef(FO[\"constructor\"+str(row['constructorId'])])\n",
    "    # add the edge connecting the Partecipation and the Constructor \n",
    "    g.add((Q_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    # create the RDF node for qualifying\n",
    "    Qualifying = URIRef(FO[\"qualifying\"+str(row['raceId'])])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Qualifying, RDF.type, FO.Qualifying))\n",
    "    # add the edge connecting the qualifyingPartecipation and the Qualifying \n",
    "    g.add((Q_partecipation, FO['partecipatedInQualif'], Qualifying))\n",
    "    \n",
    "    # create the RDF node for race\n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    # add the edge connecting the Race and the Qualifying \n",
    "    g.add((Race, FO['hasA'], Qualifying))\n",
    "    \n",
    "    # Qualifying starting dates and times are stored in the races dataframe,\n",
    "    # then we retrieve them using the matching raceId\n",
    "    Q_date_time = races[races.index == row['raceId']]\n",
    "    if(str(Q_date_time['quali_date'].values[0]) != \"\\\\N\"):\n",
    "        g.add((Qualifying, FO['hasQualiDate'], Literal(Q_date_time['quali_date'].values[0], datatype=XSD.date)))\n",
    "    if(str(Q_date_time['quali_time'].values[0]) != \"\\\\N\"):\n",
    "        g.add((Qualifying, FO['hasQualiTime'], Literal(Q_date_time['quali_time'].values[0], datatype=XSD.time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56abe1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 2.03 s\n",
      "Wall time: 2.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'qualifying.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ff574",
   "metadata": {},
   "source": [
    "# Sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9271534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "s_partecipations = pd.read_csv(sprint_resultsUrl, sep=',', index_col='resultId')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af17e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6544469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the s_partecipations dataframe\n",
    "for index, row in s_partecipations.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"s_partecipation\" + the sprint partecipation id as URI\n",
    "    S_partecipation = URIRef(FO[\"s_partecipation\"+str(index)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((S_partecipation, RDF.type, FO.SprintPartecipation))\n",
    "    g.add((S_partecipation, FO['hasCarNumber'], Literal(row['number'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasStartingGridPosition'], Literal(row['grid'], datatype=XSD.integer)))\n",
    "    if(str(row['position']) != '\\\\N'):\n",
    "        g.add((S_partecipation, FO['hasPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPositionText'], Literal(row['positionText'], datatype=XSD.string)))\n",
    "    g.add((S_partecipation, FO['hasPositionOrder'], Literal(row['positionOrder'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasPoints'], Literal(row['points'], datatype=XSD.integer)))\n",
    "    g.add((S_partecipation, FO['hasLaps'], Literal(row['laps'], datatype=XSD.integer)))\n",
    "    if(str(row['time']) != '\\\\N'):\n",
    "        g.add((S_partecipation, FO['hasResultTime'], Literal(row['time'], datatype=XSD.string)))\n",
    "    if(str(row['milliseconds']) != '\\\\N'):\n",
    "        g.add((S_partecipation, FO['hasMillisecondsResultTime'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    if(str(row['fastestLap']) != '\\\\N'):\n",
    "        g.add((S_partecipation, FO['hasFastestLap'], Literal(row['fastestLap'], datatype=XSD.integer)))\n",
    "    if(str(row['fastestLapTime']) != '\\\\N'):\n",
    "        g.add((S_partecipation, FO['hasFastestLapTime'], Literal(\"00:00:00.000\"[0:12-len(str(row['fastestLapTime']))] + \n",
    "                                                                 str(row['fastestLapTime']), datatype=XSD.time)))\n",
    "    \n",
    "    # create the RDF node for driver\n",
    "    Driver = URIRef(FO[\"driver\"+str(row['driverId'])])\n",
    "    # add the edge connecting the sprintPartecipation and the Driver\n",
    "    g.add((S_partecipation, FO['hasDriver'], Driver))\n",
    "    \n",
    "    # create the RDF node for constructor\n",
    "    Constructor = URIRef(FO[\"constructor\"+str(row['constructorId'])])\n",
    "    # add the edge connecting the sprintPartecipation and the Constructor\n",
    "    g.add((S_partecipation, FO['hasConstructor'], Constructor))\n",
    "    \n",
    "    # create the RDF node for sprint\n",
    "    Sprint = URIRef(FO[\"sprint\"+str(row['raceId'])])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Sprint, RDF.type, FO.Sprint))\n",
    "    # add the edge connecting the sprintPartecipation and the Sprint \n",
    "    g.add((S_partecipation, FO['partecipatedInSprint'], Sprint))\n",
    "    \n",
    "    # create the RDF node for race\n",
    "    Race = URIRef(FO[\"race\"+str(row['raceId'])])\n",
    "    # add the edge connecting the Race and the Sprint \n",
    "    g.add((Race, FO['hasA'], Sprint))\n",
    "    \n",
    "    # create the RDF node for status\n",
    "    Status = URIRef(FO[\"status\"+str(row['statusId'])])\n",
    "    # add the edge connecting the sprintPartecipation and the Sprint \n",
    "    g.add((S_partecipation, FO['hasStatus'], Status))\n",
    "    \n",
    "    # Sprint starting dates and times are stored in the races dataframe,\n",
    "    # then we retrieve them using the matching raceId\n",
    "    S_date_time = races[races.index == row['raceId']]\n",
    "    if(str(S_date_time['sprint_date'].values[0]) != \"\\\\N\"):\n",
    "        g.add((Sprint, FO['hasSprintDate'], Literal(S_date_time['sprint_date'].values[0], datatype=XSD.date)))\n",
    "    if(str(S_date_time['sprint_time'].values[0]) != \"\\\\N\"):\n",
    "        g.add((Sprint, FO['hasSprintTime'], Literal(S_date_time['sprint_time'].values[0], datatype=XSD.time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "111ccaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 86.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'sprint.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544125de",
   "metadata": {},
   "source": [
    "# Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c504383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "laps = pd.read_csv(lap_timesUrl, sep=',')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "283ca1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbb691b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 53s\n",
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "# id for the Lap URI\n",
    "id = 1\n",
    "#iterate over the laps dataframe\n",
    "for index, row in laps.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"lap\" + the lap id as URI\n",
    "    Lap = URIRef(FO[\"lap\"+str(id)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Lap, RDF.type, FO.Lap))\n",
    "    g.add((Lap, FO['hasLapNumber'], Literal(row['lap'], datatype=XSD.integer)))\n",
    "    g.add((Lap, FO['hasLapPosition'], Literal(row['position'], datatype=XSD.integer)))\n",
    "    g.add((Lap, FO['hasLapTime'], Literal(\"00:00:00.000\"[0:12-len(str(row['time']))] + \n",
    "                                          str(row['time']), datatype=XSD.time)))\n",
    "    g.add((Lap, FO['hasMillisecondsTime'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    \n",
    "    # Get the rows of the join dataframe with the raceId and driverId values matching those in the current row.\n",
    "    tmp = join[(join['raceId'] == row['raceId']) & (join['driverId'] == row['driverId'])]\n",
    "    #iterate over the rows found\n",
    "    for index2, row2 in tmp.iterrows():\n",
    "        # create the RDF node for racePartecipation\n",
    "        R_partecipation = URIRef(FO[\"r_partecipation\"+str(index2)])\n",
    "        # add the edge connecting the racePartecipation and the Lap \n",
    "        g.add((R_partecipation, FO['hasLap'], Lap))\n",
    "    \n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4be10ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 1min 30s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'laps.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bc8b3",
   "metadata": {},
   "source": [
    "# Pit stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "190fb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "pit_stops = pd.read_csv(pit_stopsUrl, sep=',')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c2ef890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d447acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "# id for the PitStop URI\n",
    "id = 1\n",
    "#iterate over the pit_stops dataframe\n",
    "for index, row in pit_stops.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"stop\" + the movie id as URI\n",
    "    PitStop = URIRef(FO[\"stop\"+str(id)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((PitStop, RDF.type, FO.PitStop))\n",
    "    g.add((PitStop, FO['hasStopNumber'], Literal(row['stop'], datatype=XSD.integer)))\n",
    "    g.add((PitStop, FO['hasPitStopTimeOfDay'], Literal(str(row['time']), datatype=XSD.time)))\n",
    "    g.add((PitStop, FO['hasMillisecondsTime'], Literal(row['milliseconds'], datatype=XSD.integer)))\n",
    "    g.add((PitStop, FO['hasDuration'], Literal(\"00:00:00.000\"[0:12-len(str(row['duration']))] + \n",
    "                                               str(row['duration']), datatype=XSD.time)))\n",
    "    \n",
    "    # Get the rows of the laps dataframe with the raceId, driverId and lap values matching those in the current row.\n",
    "    tmp = laps[(laps['raceId'] == row['raceId']) & (laps['driverId'] == row['driverId']) & (laps['lap'] == row['lap'])]\n",
    "    #iterate over the rows found\n",
    "    for index2, row2 in tmp.iterrows():\n",
    "        # create the RDF node for lap\n",
    "        Lap = URIRef(FO[\"lap\"+str(index2)])\n",
    "        # add the edge connecting the PitStop and the Lap \n",
    "        g.add((PitStop, FO['hasPitStopLap'], Lap))\n",
    "        \n",
    "    # Get the rows of the join dataframe with the raceId and driverId values matching those in the current row.\n",
    "    tmp2 = join[(join['raceId'] == row['raceId']) & (join['driverId'] == row['driverId'])]\n",
    "    #iterate over the rows found\n",
    "    for index2, row2 in tmp2.iterrows():\n",
    "        # create the RDF node for racePartecipation\n",
    "        R_partecipation = URIRef(FO[\"r_partecipation\"+str(index2)])\n",
    "        # add the edge connecting the racePartecipation and the PitStop \n",
    "        g.add((R_partecipation, FO['hasPitStop'], PitStop))\n",
    "    \n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaa6d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 2.08 s\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'stops.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdf6c5",
   "metadata": {},
   "source": [
    "# Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b46dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "ratings = pd.read_csv(ratingsUrl, sep=',')\n",
    "# cast year to int. If type(year) = str --> Literal= year-01-01\n",
    "# movies.astype({'year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "feff869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"fo\", FO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fad35fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 297 ms\n",
      "Wall time: 296 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "# id for the Rating URI\n",
    "id = 1\n",
    "#iterate over the ratings dataframe\n",
    "for index, row in ratings.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + \"rating\" + the movie id as URI\n",
    "    Rating = URIRef(FO[\"rating\"+str(id)])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Rating, RDF.type, FO.Rating))\n",
    "    g.add((Rating, FO['hasPeriod'], Literal(row['Period'], datatype=XSD.date)))\n",
    "    g.add((Rating, FO['hasRating'], Literal(row['Rating'], datatype=XSD.integer)))\n",
    "    g.add((Rating, FO['hasExperience'], Literal(row['Experience'], datatype=XSD.integer)))\n",
    "    g.add((Rating, FO['hasRaceCraft'], Literal(row['Race Craft'], datatype=XSD.integer)))\n",
    "    g.add((Rating, FO['hasAwareness'], Literal(row['Awareness'], datatype=XSD.integer)))\n",
    "    g.add((Rating, FO['hasPace'], Literal(row['Pace'], datatype=XSD.integer)))\n",
    "    g.add((Rating, FO['hasContractCost'], Literal(row['Contract Cost'], datatype=XSD.long)))\n",
    "    g.add((Rating, FO['hasSalary'], Literal(row['Salary'], datatype=XSD.long)))\n",
    "    g.add((Rating, FO['hasBuyout'], Literal(row['Buyout'], datatype=XSD.long)))\n",
    "    \n",
    "    # create the RDF node for season\n",
    "    Season = URIRef(FO[\"year\"+str(row['Year'])])\n",
    "    # add the edge connecting the Rating and the Season \n",
    "    g.add((Rating, FO['inSeason'], Season))\n",
    "    \n",
    "    # in ratings csv names are full-names, then they are splitted in forename and surname\n",
    "    name = str(row['Driver']).split(' ')\n",
    "    forename = name[0].strip()\n",
    "    surname = name[1].strip()\n",
    "    # Get the rows of the drivers dataframe with the forename value (rating csv) contained in forename column of the current row (driver csv).\n",
    "    subCsv = drivers[drivers['forename'].str.contains(forename, case=False)]\n",
    "    # If exists at least one row in subCsv that contain also the surname of the rating\n",
    "    if((subCsv['surname'].str.contains(surname, case=False)).any() == True):\n",
    "        # Get the rows of the drivers dataframe with the forename and surname values contained in the matching column of the current row.\n",
    "        dId = drivers[(drivers['forename'].str.contains(forename, case=False)) & (drivers['surname'].str.contains(surname, case=False))].index.values[0]\n",
    "        # create the RDF node for driver\n",
    "        Driver = URIRef(FO[\"driver\"+str(dId)])\n",
    "        # add the edge connecting the Rating and the Driver \n",
    "        g.add((Rating, FO['hasDriver'], Driver))\n",
    "        \n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dc07d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 51.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'ratings.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c823e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
